<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>English Tutor AI - Natural Voice</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Poppins:wght@400;500;600&display=swap" rel="stylesheet">
    <script src="https://cdn.tailwindcss.com"></script>
    <script>
        tailwind.config = {
            theme: {
                extend: {
                    colors: {
                        primary: '#4361ee',
                        'primary-light': '#4895ef',
                        secondary: '#3a0ca3',
                        accent: '#f72585',
                        success: '#4cc9f0',
                        correction: '#2ec4b6',
                    },
                    fontFamily: {
                        sans: ['Inter', 'sans-serif'],
                        display: ['Poppins', 'sans-serif'],
                    }
                }
            }
        }
    </script>
    <style>
        body {
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
            min-height: 100vh;
        }

        .chat-container {
            height: calc(100vh - 180px);
            min-height: 500px;
        }

        .message {
            animation: fadeIn 0.3s ease;
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }

        .voice-btn.listening {
            background: linear-gradient(to right, #f72585, #ff4d6d);
            animation: pulse 1.5s infinite;
        }

        .voice-btn.speaking {
            background: linear-gradient(to right, #4cc9f0, #4361ee);
            box-shadow: 0 0 15px #4cc9f0;
        }

        @keyframes pulse {
            0% { box-shadow: 0 0 0 0 rgba(239, 35, 60, 0.7); }
            70% { box-shadow: 0 0 0 15px rgba(239, 35, 60, 0); }
            100% { box-shadow: 0 0 0 0 rgba(239, 35, 60, 0); }
        }

        /* Sound Wave Animation */
        .wave-bar {
            animation: soundWave 1.2s ease infinite;
        }
        .wave-bar:nth-child(2) { animation-delay: 0.1s; }
        .wave-bar:nth-child(3) { animation-delay: 0.2s; }
        .wave-bar:nth-child(4) { animation-delay: 0.3s; }
        .wave-bar:nth-child(5) { animation-delay: 0.4s; }

        @keyframes soundWave {
            0%, 100% { height: 8px; }
            50% { height: 24px; }
        }

        .typing-indicator span {
            animation: blink 1.4s infinite both;
        }
        .typing-indicator span:nth-child(2) { animation-delay: 0.2s; }
        .typing-indicator span:nth-child(3) { animation-delay: 0.4s; }

        @keyframes blink {
            0% { opacity: 0.2; }
            20% { opacity: 1; }
            100% { opacity: 0.2; }
        }

        /* Scrollbar styling */
        .chat-messages::-webkit-scrollbar {
            width: 6px;
        }
        .chat-messages::-webkit-scrollbar-track {
            background: #f1f1f1;
        }
        .chat-messages::-webkit-scrollbar-thumb {
            background: #c1c1c1;
            border-radius: 10px;
        }
    </style>
</head>
<body class="flex flex-col p-4 md:p-6 font-sans text-gray-800">

    <div class="max-w-4xl mx-auto w-full flex flex-col h-full">
        <!-- Header -->
        <header class="flex justify-between items-center mb-6">
            <div class="flex items-center gap-3">
                <div class="bg-white p-2 rounded-lg shadow-sm">
                    <i class="fas fa-graduation-cap text-3xl text-primary"></i>
                </div>
                <div>
                    <h1 class="font-display font-bold text-2xl text-transparent bg-clip-text bg-gradient-to-r from-primary to-secondary">English Tutor AI</h1>
                    <p class="text-xs text-gray-500 font-medium">Powered by Gemini 2.5 Flash</p>
                </div>
            </div>
            <button id="settingsBtn" class="bg-white hover:bg-primary hover:text-white w-12 h-12 rounded-full flex items-center justify-center text-primary shadow-md transition-all duration-300 transform hover:rotate-90">
                <i class="fas fa-cog text-xl"></i>
            </button>
        </header>

        <!-- Main Content -->
        <main class="flex-1 flex flex-col gap-6">
            <div class="bg-white rounded-2xl shadow-xl overflow-hidden flex flex-col chat-container border border-gray-100">
                
                <!-- Chat Header -->
                <div class="bg-gradient-to-r from-primary to-secondary text-white p-4 flex items-center gap-4 shadow-md z-10">
                    <div class="relative">
                        <img src="https://images.unsplash.com/photo-1535713875002-d1d0cf377fde?ixlib=rb-4.0.3&auto=format&fit=crop&w=100&q=80" alt="Avatar" class="w-12 h-12 rounded-full border-2 border-white/50 object-cover">
                        <div class="absolute bottom-0 right-0 w-3 h-3 bg-green-400 rounded-full border-2 border-primary"></div>
                    </div>
                    <div>
                        <h2 class="font-display font-semibold text-lg leading-tight" id="botNameDisplay">Professor Atlas</h2>
                        <p class="text-xs text-blue-100 opacity-90">Native English Voice • Active</p>
                    </div>
                </div>

                <!-- Messages Area -->
                <div class="flex-1 overflow-y-auto p-6 bg-gray-50 flex flex-col gap-4 chat-messages" id="chatMessages">
                    <!-- Initial Message -->
                    <div class="message self-start max-w-[85%] bg-white border border-gray-200 rounded-2xl rounded-tl-none p-4 shadow-sm">
                        <div class="flex justify-between items-center mb-2">
                            <span class="font-bold text-sm text-primary">Professor Atlas</span>
                            <span class="text-xs text-gray-400">Now</span>
                        </div>
                        <div class="text-gray-700 leading-relaxed">
                            Hello! I'm your AI English tutor. I can hear you and speak with a <b>natural human voice</b>. 
                            <br><br>
                            Please click the settings gear <i class="fas fa-cog text-gray-400"></i> to add your API Key first, then press the microphone to start talking!
                        </div>
                    </div>
                </div>

                <!-- Typing Indicator (Hidden by default) -->
                <div id="typingIndicator" class="hidden px-6 py-2 bg-gray-50">
                    <div class="flex items-center gap-2 text-gray-500 text-sm">
                        <span class="font-medium" id="statusText">Thinking...</span>
                        <div class="typing-indicator flex gap-1">
                            <span class="w-1.5 h-1.5 bg-gray-400 rounded-full"></span>
                            <span class="w-1.5 h-1.5 bg-gray-400 rounded-full"></span>
                            <span class="w-1.5 h-1.5 bg-gray-400 rounded-full"></span>
                        </div>
                    </div>
                </div>

                <!-- Controls Area -->
                <div class="bg-white p-6 border-t border-gray-100 flex flex-col items-center gap-4 relative">
                    <!-- Sound Wave Visualizer (Hidden by default) -->
                    <div class="flex items-center justify-center gap-1 h-6 absolute -top-3 bg-white px-3 rounded-full shadow-sm border border-gray-100" id="soundWave" style="display: none;">
                        <div class="wave-bar w-1 bg-primary rounded-full h-2"></div>
                        <div class="wave-bar w-1 bg-primary rounded-full h-2"></div>
                        <div class="wave-bar w-1 bg-primary rounded-full h-2"></div>
                        <div class="wave-bar w-1 bg-primary rounded-full h-2"></div>
                        <div class="wave-bar w-1 bg-primary rounded-full h-2"></div>
                    </div>

                    <button id="voiceBtn" class="voice-btn w-16 h-16 rounded-full bg-gradient-to-r from-primary to-primary-light text-white text-2xl shadow-lg shadow-blue-500/30 flex items-center justify-center transition-all duration-300 hover:scale-105 active:scale-95 disabled:opacity-50 disabled:cursor-not-allowed">
                        <i class="fas fa-microphone"></i>
                    </button>
                    
                    <p class="text-sm text-gray-500 font-medium" id="voiceStatus">Press to speak</p>
                </div>
            </div>
        </main>

        <footer class="text-center mt-6 text-gray-400 text-xs">
            <p>English Tutor AI • Requires Google Gemini API Key for Natural Voice</p>
        </footer>
    </div>

    <!-- Settings Modal -->
    <div id="settingsModal" class="fixed inset-0 bg-black/60 backdrop-blur-sm z-50 hidden items-center justify-center p-4">
        <div class="bg-white rounded-2xl w-full max-w-md p-6 shadow-2xl transform transition-all scale-100">
            <div class="flex justify-between items-center mb-6">
                <h2 class="font-display font-bold text-xl text-gray-800">Settings</h2>
                <button id="closeModal" class="text-gray-400 hover:text-red-500 transition-colors">
                    <i class="fas fa-times text-xl"></i>
                </button>
            </div>
            
            <div class="space-y-4">
                <div>
                    <label class="block text-sm font-semibold text-gray-700 mb-2">Gemini API Key</label>
                    <input type="password" id="apiKey" class="w-full p-3 border border-gray-300 rounded-xl focus:ring-2 focus:ring-primary focus:border-primary outline-none transition-all" placeholder="Enter your API Key here">
                    <p class="text-xs text-gray-500 mt-2 flex items-center gap-1">
                        <i class="fas fa-info-circle"></i> 
                        Get a free key at <a href="https://aistudio.google.com/app/apikey" target="_blank" class="text-primary hover:underline">Google AI Studio</a>
                    </p>
                </div>

                <div>
                    <label class="block text-sm font-semibold text-gray-700 mb-2">Voice Model</label>
                    <select id="voiceSelect" class="w-full p-3 border border-gray-300 rounded-xl focus:ring-2 focus:ring-primary outline-none bg-white">
                        <option value="Kore">Kore (Female - Natural)</option>
                        <option value="Fenrir">Fenrir (Male - Natural)</option>
                        <option value="Puck">Puck (Male - Natural)</option>
                        <option value="Aoede">Aoede (Female - Natural)</option>
                        <option value="browser">Browser Default (Robotic Fallback)</option>
                    </select>
                </div>

                <div class="pt-4 flex justify-end gap-3">
                    <button id="clearChatBtn" class="px-4 py-2 text-gray-600 hover:bg-gray-100 rounded-lg transition-colors font-medium text-sm">Clear Chat</button>
                    <button id="saveSettingsBtn" class="px-6 py-2 bg-primary hover:bg-secondary text-white rounded-lg transition-colors font-medium shadow-lg shadow-blue-500/20">Save Configuration</button>
                </div>
            </div>
        </div>
    </div>

    <!-- Notification Toast -->
    <div id="notification" class="fixed bottom-6 left-1/2 transform -translate-x-1/2 bg-gray-800 text-white px-6 py-3 rounded-full shadow-lg flex items-center gap-3 transition-all duration-300 translate-y-20 opacity-0 z-50">
        <i class="fas fa-check-circle text-green-400"></i>
        <span id="notificationText" class="text-sm font-medium">Settings saved</span>
    </div>

    <script>
        // DOM Elements
        const chatMessages = document.getElementById('chatMessages');
        const voiceBtn = document.getElementById('voiceBtn');
        const voiceStatus = document.getElementById('voiceStatus');
        const soundWave = document.getElementById('soundWave');
        const settingsBtn = document.getElementById('settingsBtn');
        const settingsModal = document.getElementById('settingsModal');
        const closeModal = document.getElementById('closeModal');
        const apiKeyInput = document.getElementById('apiKey');
        const voiceSelect = document.getElementById('voiceSelect');
        const saveSettingsBtn = document.getElementById('saveSettingsBtn');
        const clearChatBtn = document.getElementById('clearChatBtn');
        const notification = document.getElementById('notification');
        const notificationText = document.getElementById('notificationText');
        const typingIndicator = document.getElementById('typingIndicator');
        const statusText = document.getElementById('statusText');

        // State
        let state = {
            isListening: false,
            apiKey: '',
            voice: 'Kore',
            history: []
        };

        let recognition = null;
        let audioContext = null;

        // --- Initialization ---
        document.addEventListener('DOMContentLoaded', () => {
            loadSettings();
            initSpeechRecognition();
            setupEventListeners();
        });

        function loadSettings() {
            const savedKey = localStorage.getItem('tutor_api_key');
            const savedVoice = localStorage.getItem('tutor_voice');
            if (savedKey) {
                state.apiKey = savedKey;
                apiKeyInput.value = savedKey;
            }
            if (savedVoice) {
                state.voice = savedVoice;
                voiceSelect.value = savedVoice;
            }
        }

        function setupEventListeners() {
            voiceBtn.addEventListener('click', toggleListening);
            settingsBtn.addEventListener('click', () => settingsModal.classList.remove('hidden', 'flex'));
            settingsBtn.addEventListener('click', () => settingsModal.classList.add('flex'));
            closeModal.addEventListener('click', () => settingsModal.classList.add('hidden'));
            saveSettingsBtn.addEventListener('click', saveSettings);
            clearChatBtn.addEventListener('click', () => {
                chatMessages.innerHTML = '';
                state.history = [];
                showNotification('Chat cleared');
                settingsModal.classList.add('hidden');
            });
            
            // Close modal on outside click
            settingsModal.addEventListener('click', (e) => {
                if (e.target === settingsModal) settingsModal.classList.add('hidden');
            });
        }

        // --- Speech Recognition (Browser Web Speech API) ---
        function initSpeechRecognition() {
            if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
                const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                recognition = new SpeechRecognition();
                recognition.continuous = false;
                recognition.interimResults = false;
                recognition.lang = 'en-US'; // User speaks English

                recognition.onstart = () => {
                    state.isListening = true;
                    updateUIState('listening');
                };

                recognition.onresult = (event) => {
                    const transcript = event.results[0][0].transcript;
                    addUserMessage(transcript);
                    processWithGemini(transcript);
                };

                recognition.onerror = (event) => {
                    console.error('Speech error:', event.error);
                    updateUIState('idle');
                    showNotification('Microphone error. Try again.', 'error');
                };

                recognition.onend = () => {
                    if (state.isListening) {
                        state.isListening = false;
                        // Don't reset UI to idle immediately if we are processing
                    }
                };
            } else {
                voiceBtn.disabled = true;
                voiceStatus.textContent = 'Browser not supported';
                showNotification('Use Chrome for voice features', 'error');
            }
        }

        function toggleListening() {
            if (!recognition) return;
            if (state.isListening) {
                recognition.stop();
            } else {
                // Ensure audio context is ready (needed for playback later)
                if (!audioContext) audioContext = new (window.AudioContext || window.webkitAudioContext)();
                recognition.start();
            }
        }

        // --- Gemini Interaction (Text & Audio) ---

        async function processWithGemini(userText) {
            if (!state.apiKey) {
                addBotMessage("Please enter your API Key in settings to start chatting!");
                updateUIState('idle');
                return;
            }

            updateUIState('thinking');

            // 1. Get Text Response
            try {
                const textResponse = await fetchGeminiText(userText);
                
                // Add message to chat but allow HTML for corrections
                addBotMessage(textResponse);
                
                // 2. Get Audio Response
                updateUIState('generating_audio');
                
                if (state.voice === 'browser') {
                    speakNative(textResponse); // Fallback
                } else {
                    await speakGemini(textResponse); // Natural Voice
                }

            } catch (error) {
                console.error(error);
                addBotMessage("I encountered an error connecting to the AI. Check your API Key.");
                updateUIState('idle');
            }
        }

        async function fetchGeminiText(input) {
            const url = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview:generateContent?key=${state.apiKey}`;
            
            // Context management
            const contextPrompt = `
                You are a friendly, encouraging English Tutor named Professor Atlas. 
                Your goal is to help a Spanish speaker improve their English.
                1. If the user makes a grammar mistake, correct it gently. Use bold text (<b>) for corrections.
                2. Keep your responses concise (2-3 sentences max) so the voice conversation flows naturally.
                3. Respond in English.
                User said: "${input}"
            `;

            const payload = {
                contents: [{ parts: [{ text: contextPrompt }] }]
            };

            const response = await fetch(url, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(payload)
            });

            if (!response.ok) throw new Error('Gemini Text API Error');
            
            const data = await response.json();
            return data.candidates[0].content.parts[0].text;
        }

        async function speakGemini(text) {
            // Remove HTML tags for speech
            const cleanText = text.replace(/<[^>]*>/g, '');
            
            const url = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent?key=${state.apiKey}`;
            
            const payload = {
                contents: [{ parts: [{ text: cleanText }] }],
                generationConfig: {
                    responseModalities: ["AUDIO"],
                    speechConfig: {
                        voiceConfig: {
                            prebuiltVoiceConfig: {
                                voiceName: state.voice
                            }
                        }
                    }
                }
            };

            try {
                const response = await fetch(url, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });

                if (!response.ok) throw new Error('Gemini TTS API Error');

                const data = await response.json();
                
                if (data.candidates && data.candidates[0].content.parts[0].inlineData) {
                    const base64Audio = data.candidates[0].content.parts[0].inlineData.data;
                    await playPCM16(base64Audio);
                } else {
                    throw new Error('No audio data received');
                }
            } catch (e) {
                console.error("TTS Failed, falling back", e);
                showNotification("AI Voice failed, using fallback", "error");
                speakNative(cleanText); // Fallback to robotic voice if API fails
            }
        }

        // --- Audio Processing (PCM -> WAV -> Play) ---
        
        async function playPCM16(base64Data) {
            updateUIState('speaking');
            
            const binaryString = window.atob(base64Data);
            const len = binaryString.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }
            
            // PCM data from Gemini is 24kHz, Mono, 16-bit (usually)
            // We need to wrap it in a WAV container to play via Audio element or decode via Context
            const wavBytes = getWavBytes(bytes.buffer, {
                isFloat: false,       // integer
                numChannels: 1,       // mono
                sampleRate: 24000,    // Gemini TTS standard
            });

            const blob = new Blob([wavBytes], { type: 'audio/wav' });
            const audioUrl = URL.createObjectURL(blob);
            const audio = new Audio(audioUrl);
            
            audio.onended = () => {
                updateUIState('idle');
                URL.revokeObjectURL(audioUrl);
            };
            
            await audio.play();
        }

        // Utility to create WAV header for raw PCM data
        function getWavBytes(buffer, options) {
            const type = options.isFloat ? Float32Array : Uint16Array;
            const numFrames = buffer.byteLength / type.BYTES_PER_ELEMENT;

            const headerBytes = getWavHeader(Object.assign({}, options, { numFrames }));
            const wavBytes = new Uint8Array(headerBytes.length + buffer.byteLength);

            // prepend header, then add pcm bytes
            wavBytes.set(headerBytes, 0);
            wavBytes.set(new Uint8Array(buffer), headerBytes.length);

            return wavBytes;
        }

        function getWavHeader(options) {
            const numFrames = options.numFrames;
            const numChannels = options.numChannels || 2;
            const sampleRate = options.sampleRate || 44100;
            const bytesPerSample = options.isFloat ? 4 : 2;
            const format = options.isFloat ? 3 : 1;

            const blockAlign = numChannels * bytesPerSample;
            const byteRate = sampleRate * blockAlign;
            const dataSize = numFrames * blockAlign;

            const buffer = new ArrayBuffer(44);
            const dv = new DataView(buffer);

            let p = 0;

            function writeString(s) {
                for (let i = 0; i < s.length; i++) {
                    dv.setUint8(p + i, s.charCodeAt(i));
                }
                p += s.length;
            }

            function writeUint32(d) {
                dv.setUint32(p, d, true);
                p += 4;
            }

            function writeUint16(d) {
                dv.setUint16(p, d, true);
                p += 2;
            }

            writeString('RIFF');              // ChunkID
            writeUint32(dataSize + 36);       // ChunkSize
            writeString('WAVE');              // Format
            writeString('fmt ');              // Subchunk1ID
            writeUint32(16);                  // Subchunk1Size
            writeUint16(format);              // AudioFormat
            writeUint16(numChannels);         // NumChannels
            writeUint32(sampleRate);          // SampleRate
            writeUint32(byteRate);            // ByteRate
            writeUint16(blockAlign);          // BlockAlign
            writeUint16(bytesPerSample * 8);  // BitsPerSample
            writeString('data');              // Subchunk2ID
            writeUint32(dataSize);            // Subchunk2Size

            return new Uint8Array(buffer);
        }

        // --- Fallback Native TTS ---
        function speakNative(text) {
            updateUIState('speaking');
            const utterance = new SpeechSynthesisUtterance(text);
            utterance.lang = 'en-US';
            utterance.rate = 1;
            
            // Try to find a non-default voice
            const voices = speechSynthesis.getVoices();
            const preferred = voices.find(v => v.name.includes('Google US English')) || voices.find(v => v.lang.startsWith('en'));
            if (preferred) utterance.voice = preferred;

            utterance.onend = () => updateUIState('idle');
            speechSynthesis.speak(utterance);
        }

        // --- UI Logic ---

        function addUserMessage(text) {
            const div = document.createElement('div');
            div.className = 'message self-end max-w-[85%] bg-primary text-white rounded-2xl rounded-tr-none p-4 shadow-md';
            div.innerHTML = `
                <div class="text-sm opacity-80 mb-1 text-right">You</div>
                <div>${text}</div>
            `;
            chatMessages.appendChild(div);
            scrollToBottom();
        }

        function addBotMessage(html) {
            const div = document.createElement('div');
            div.className = 'message self-start max-w-[85%] bg-white border border-gray-200 rounded-2xl rounded-tl-none p-4 shadow-sm';
            div.innerHTML = `
                <div class="font-bold text-sm text-primary mb-1">Professor Atlas</div>
                <div class="text-gray-700 leading-relaxed">${html}</div>
            `;
            chatMessages.appendChild(div);
            scrollToBottom();
        }

        function updateUIState(status) {
            // Reset classes
            voiceBtn.classList.remove('listening', 'speaking');
            soundWave.style.display = 'none';
            typingIndicator.classList.add('hidden');
            
            switch(status) {
                case 'listening':
                    voiceBtn.classList.add('listening');
                    voiceBtn.innerHTML = '<i class="fas fa-stop"></i>';
                    voiceStatus.textContent = 'Listening...';
                    soundWave.style.display = 'flex';
                    break;
                case 'thinking':
                    voiceBtn.disabled = true;
                    typingIndicator.classList.remove('hidden');
                    statusText.textContent = 'Thinking...';
                    voiceStatus.textContent = 'Processing';
                    break;
                case 'generating_audio':
                    voiceBtn.disabled = true;
                    typingIndicator.classList.remove('hidden');
                    statusText.textContent = 'Generating Voice...';
                    break;
                case 'speaking':
                    voiceBtn.classList.add('speaking');
                    voiceBtn.innerHTML = '<i class="fas fa-volume-up"></i>';
                    voiceBtn.disabled = false;
                    voiceStatus.textContent = 'Speaking...';
                    soundWave.style.display = 'flex'; // Visualize speaking too
                    break;
                case 'idle':
                default:
                    voiceBtn.innerHTML = '<i class="fas fa-microphone"></i>';
                    voiceBtn.disabled = false;
                    voiceStatus.textContent = 'Press to speak';
                    break;
            }
        }

        function scrollToBottom() {
            chatMessages.scrollTop = chatMessages.scrollHeight;
        }

        function saveSettings() {
            const key = apiKeyInput.value.trim();
            const voice = voiceSelect.value;
            
            if (key) {
                state.apiKey = key;
                localStorage.setItem('tutor_api_key', key);
            }
            
            state.voice = voice;
            localStorage.setItem('tutor_voice', voice);
            
            settingsModal.classList.add('hidden');
            showNotification('Configuration saved!');
        }

        function showNotification(text, type = 'success') {
            notificationText.textContent = text;
            const icon = notification.querySelector('i');
            icon.className = type === 'success' ? 'fas fa-check-circle text-green-400' : 'fas fa-exclamation-circle text-red-400';
            
            notification.classList.remove('translate-y-20', 'opacity-0');
            setTimeout(() => {
                notification.classList.add('translate-y-20', 'opacity-0');
            }, 3000);
        }

        // Initialize voices for fallback
        speechSynthesis.onvoiceschanged = () => {};
    </script>
</body>
</html>
