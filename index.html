<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>English Tutor AI - Natural Voice</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Poppins:wght@400;500;600&display=swap" rel="stylesheet">
    <script src="https://cdn.tailwindcss.com"></script>
    <script>
        tailwind.config = {
            theme: {
                extend: {
                    colors: {
                        primary: '#4361ee',
                        'primary-light': '#4895ef',
                        secondary: '#3a0ca3',
                        accent: '#f72585',
                        success: '#4cc9f0',
                        correction: '#2ec4b6',
                    },
                    fontFamily: {
                        sans: ['Inter', 'sans-serif'],
                        display: ['Poppins', 'sans-serif'],
                    }
                }
            }
        }
    </script>
    <style>
        body {
            background: linear-gradient(135deg, #e0c3fc 0%, #8ec5fc 100%);
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            overscroll-behavior: none;
        }

        .chat-container {
            height: 100dvh;
            max-height: 100dvh;
        }
        
        @media (min-width: 768px) {
            .chat-container {
                height: 85vh;
                min-height: 600px;
                max-height: 800px;
            }
        }

        .message {
            animation: fadeIn 0.3s ease;
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }

        /* Microphone/Send Button States */
        .voice-btn {
            transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
        }

        .voice-btn.listening {
            background: #10b981 !important; /* Green for Send */
            box-shadow: 0 0 0 8px rgba(16, 185, 129, 0.3);
            transform: scale(1.1);
        }
        
        .voice-btn.listening i {
            animation: bounce-right 1s infinite;
        }

        @keyframes bounce-right {
            0%, 100% { transform: translateX(0); }
            50% { transform: translateX(3px); }
        }

        .voice-btn.speaking {
            background: linear-gradient(to right, #4cc9f0, #4361ee);
            box-shadow: 0 0 20px rgba(67, 97, 238, 0.4);
        }

        /* Sound Wave Animation */
        .wave-bar {
            animation: soundWave 1.2s ease infinite;
        }
        .wave-bar:nth-child(2) { animation-delay: 0.1s; }
        .wave-bar:nth-child(3) { animation-delay: 0.2s; }
        .wave-bar:nth-child(4) { animation-delay: 0.3s; }
        .wave-bar:nth-child(5) { animation-delay: 0.4s; }

        @keyframes soundWave {
            0%, 100% { height: 8px; }
            50% { height: 24px; }
        }

        .typing-indicator span {
            animation: blink 1.4s infinite both;
        }
        .typing-indicator span:nth-child(2) { animation-delay: 0.2s; }
        .typing-indicator span:nth-child(3) { animation-delay: 0.4s; }

        @keyframes blink {
            0% { opacity: 0.2; }
            20% { opacity: 1; }
            100% { opacity: 0.2; }
        }

        /* Scrollbar styling */
        .chat-messages::-webkit-scrollbar {
            width: 6px;
        }
        .chat-messages::-webkit-scrollbar-track {
            background: #f1f1f1;
        }
        .chat-messages::-webkit-scrollbar-thumb {
            background: #c1c1c1;
            border-radius: 10px;
        }

        /* Custom error formatting */
        .error-mark {
            color: #ef4444; /* red-500 */
            text-decoration: line-through;
            opacity: 0.9;
            margin-right: 4px;
            font-weight: 500;
        }
        
        .correction-mark {
            color: #16a34a; /* green-600 */
            font-weight: 700;
        }

        /* Live Transcript Preview */
        .transcript-preview {
            position: absolute;
            bottom: 110px;
            left: 20px;
            right: 20px;
            background: rgba(255, 255, 255, 0.95);
            color: #333;
            padding: 12px 16px;
            border-radius: 16px;
            font-size: 15px;
            text-align: center;
            box-shadow: 0 4px 15px rgba(0,0,0,0.1);
            border: 1px solid #e5e7eb;
            z-index: 20;
            display: none;
            max-height: 100px;
            overflow-y: auto;
        }
    </style>
</head>
<body class="font-sans text-gray-800 p-0 md:p-4">

    <div class="max-w-md w-full mx-auto relative h-full">
        
        <!-- Main Content -->
        <main class="w-full h-full">
            <div class="bg-white md:rounded-3xl shadow-2xl overflow-hidden flex flex-col chat-container border-0 md:border border-white/50 backdrop-blur-sm">
                
                <!-- Chat Header -->
                <div class="bg-white p-4 flex items-center justify-between border-b border-gray-100 shadow-sm z-10 sticky top-0">
                    <div class="flex items-center gap-4">
                        <div class="relative">
                            <img src="https://images.unsplash.com/photo-1494790108377-be9c29b29330?ixlib=rb-4.0.3&auto=format&fit=crop&w=150&q=80" alt="Avatar" class="w-10 h-10 md:w-12 md:h-12 rounded-full border-2 border-primary p-0.5 object-cover">
                            <div class="absolute bottom-0 right-0 w-3 h-3 bg-green-500 rounded-full border-2 border-white"></div>
                        </div>
                        <div>
                            <h2 class="font-display font-bold text-lg text-gray-800 leading-tight" id="botNameDisplay">Professor Emma</h2>
                            <div class="flex items-center gap-2">
                                <p class="text-xs text-primary font-medium bg-blue-50 px-2 py-0.5 rounded-full inline-block">AI English Tutor</p>
                            </div>
                        </div>
                    </div>
                    
                    <button id="settingsBtn" class="w-10 h-10 rounded-full bg-gray-50 hover:bg-gray-100 flex items-center justify-center text-gray-500 transition-all duration-300">
                        <i class="fas fa-cog text-lg"></i>
                    </button>
                </div>

                <!-- Messages Area -->
                <div class="flex-1 overflow-y-auto p-4 bg-[#f8faff] flex flex-col gap-5 chat-messages" id="chatMessages">
                    <!-- Initial Message -->
                    <div class="message self-start w-[90%] bg-white border border-gray-100 rounded-2xl rounded-tl-none p-4 shadow-sm relative pb-8">
                        <div class="text-content text-gray-700 leading-relaxed text-[15px]">
                            Hello! I'm <b>Emma</b>. 
                            <br><br>
                            <b>How to use:</b>
                            <br>
                            1. Tap <i class="fas fa-microphone text-primary"></i> to start speaking.
                            <br>
                            2. When you are done, tap <i class="fas fa-paper-plane text-green-500"></i> to send.
                            <br><br>
                            Please set your API Key to begin!
                        </div>
                    </div>
                </div>

                <!-- Live Transcript Preview -->
                <div id="transcriptPreview" class="transcript-preview">
                    Listening...
                </div>

                <!-- Typing Indicator -->
                <div id="typingIndicator" class="hidden px-6 py-3 bg-[#f8faff] text-center border-t border-gray-100">
                    <div class="inline-flex items-center gap-3 text-gray-400 text-xs font-medium uppercase tracking-wider bg-white px-4 py-2 rounded-full shadow-sm">
                        <span id="statusText">Emma is thinking...</span>
                        <div class="typing-indicator flex gap-1">
                            <span class="w-1.5 h-1.5 bg-primary rounded-full"></span>
                            <span class="w-1.5 h-1.5 bg-primary rounded-full"></span>
                            <span class="w-1.5 h-1.5 bg-primary rounded-full"></span>
                        </div>
                    </div>
                </div>

                <!-- Controls Area -->
                <div class="bg-white p-6 pb-8 md:pb-8 border-t border-gray-50 flex flex-col items-center gap-4 relative md:rounded-b-3xl safe-area-bottom">
                    <!-- Sound Wave Visualizer -->
                    <div class="flex items-center justify-center gap-1 h-8 absolute -top-4 bg-white px-4 rounded-full shadow-md border border-gray-50" id="soundWave" style="display: none;">
                        <div class="wave-bar w-1 bg-gradient-to-t from-primary to-accent rounded-full h-3"></div>
                        <div class="wave-bar w-1 bg-gradient-to-t from-primary to-accent rounded-full h-3"></div>
                        <div class="wave-bar w-1 bg-gradient-to-t from-primary to-accent rounded-full h-3"></div>
                        <div class="wave-bar w-1 bg-gradient-to-t from-primary to-accent rounded-full h-3"></div>
                        <div class="wave-bar w-1 bg-gradient-to-t from-primary to-accent rounded-full h-3"></div>
                    </div>

                    <button id="voiceBtn" class="voice-btn w-20 h-20 rounded-full bg-gradient-to-br from-primary to-secondary text-white text-3xl shadow-xl shadow-indigo-500/20 flex items-center justify-center active:scale-95 disabled:opacity-70 disabled:scale-95">
                        <i class="fas fa-microphone"></i>
                    </button>
                    
                    <p class="text-sm text-gray-400 font-medium" id="voiceStatus">Tap to speak</p>
                </div>
            </div>
        </main>
    </div>

    <!-- Settings Modal -->
    <div id="settingsModal" class="fixed inset-0 bg-black/60 backdrop-blur-md z-50 hidden items-center justify-center p-4">
        <div class="bg-white rounded-3xl w-full max-w-sm p-6 shadow-2xl transform transition-all scale-100">
            <div class="flex justify-between items-center mb-6">
                <h2 class="font-display font-bold text-xl text-gray-800">Settings</h2>
                <button id="closeModal" class="w-8 h-8 rounded-full bg-gray-100 flex items-center justify-center text-gray-500 hover:bg-red-50 hover:text-red-500 transition-colors">
                    <i class="fas fa-times"></i>
                </button>
            </div>
            
            <div class="space-y-5">
                <div>
                    <label class="block text-xs font-bold text-gray-500 uppercase tracking-wide mb-2">Gemini API Key</label>
                    <input type="password" id="apiKey" class="w-full p-3 bg-gray-50 border border-gray-200 rounded-xl focus:ring-2 focus:ring-primary focus:bg-white focus:border-transparent outline-none transition-all text-sm" placeholder="Paste key here...">
                    <p class="text-xs text-gray-400 mt-2 flex items-center gap-1">
                        <i class="fas fa-key"></i> 
                        Required for AI voice & logic
                    </p>
                </div>

                <div>
                    <label class="block text-xs font-bold text-gray-500 uppercase tracking-wide mb-2">Voice Preference</label>
                    <div class="relative">
                        <select id="voiceSelect" class="w-full p-3 bg-gray-50 border border-gray-200 rounded-xl focus:ring-2 focus:ring-primary outline-none appearance-none text-sm">
                            <option value="Kore">Emma (Natural Female)</option>
                            <option value="Aoede">Sophia (Natural Female)</option>
                            <option value="Fenrir">Liam (Natural Male)</option>
                            <option value="Puck">Noah (Natural Male)</option>
                        </select>
                        <div class="absolute right-3 top-3 text-gray-400 pointer-events-none">
                            <i class="fas fa-chevron-down"></i>
                        </div>
                    </div>
                </div>

                <div class="pt-2 flex flex-col gap-3">
                    <button id="saveSettingsBtn" class="w-full py-3 bg-primary hover:bg-secondary text-white rounded-xl transition-all font-semibold shadow-lg shadow-blue-500/30 active:scale-[0.98]">Save Changes</button>
                    <button id="clearChatBtn" class="w-full py-3 text-gray-500 hover:text-gray-700 hover:bg-gray-50 rounded-xl transition-colors font-medium text-sm">Clear Conversation</button>
                </div>
            </div>
        </div>
    </div>

    <!-- Notification Toast -->
    <div id="notification" class="fixed top-6 left-1/2 transform -translate-x-1/2 bg-white/90 backdrop-blur border border-gray-200 text-gray-800 px-6 py-3 rounded-full shadow-lg flex items-center gap-3 transition-all duration-300 -translate-y-24 opacity-0 z-50">
        <div class="w-6 h-6 rounded-full bg-green-100 flex items-center justify-center text-green-500">
            <i class="fas fa-check text-xs"></i>
        </div>
        <span id="notificationText" class="text-sm font-semibold">Settings saved</span>
    </div>

    <script>
        // DOM Elements
        const chatMessages = document.getElementById('chatMessages');
        const voiceBtn = document.getElementById('voiceBtn');
        const voiceStatus = document.getElementById('voiceStatus');
        const soundWave = document.getElementById('soundWave');
        const settingsBtn = document.getElementById('settingsBtn');
        const settingsModal = document.getElementById('settingsModal');
        const closeModal = document.getElementById('closeModal');
        const apiKeyInput = document.getElementById('apiKey');
        const voiceSelect = document.getElementById('voiceSelect');
        const saveSettingsBtn = document.getElementById('saveSettingsBtn');
        const clearChatBtn = document.getElementById('clearChatBtn');
        const notification = document.getElementById('notification');
        const notificationText = document.getElementById('notificationText');
        const typingIndicator = document.getElementById('typingIndicator');
        const statusText = document.getElementById('statusText');
        const transcriptPreview = document.getElementById('transcriptPreview');

        // State
        let state = {
            isListening: false,
            shouldBeListening: false,
            apiKey: '',
            voice: 'Kore',
            savedTranscript: '', // Previous sessions
            currentSessionText: '', // Current active speech
        };

        let recognition = null;
        let audioContext = null;

        // --- Initialization ---
        document.addEventListener('DOMContentLoaded', () => {
            loadSettings();
            initSpeechRecognition();
            setupEventListeners();
        });

        function loadSettings() {
            const savedKey = localStorage.getItem('tutor_api_key');
            const savedVoice = localStorage.getItem('tutor_voice');
            if (savedKey) {
                state.apiKey = savedKey;
                apiKeyInput.value = savedKey;
            }
            if (savedVoice) {
                state.voice = savedVoice;
                voiceSelect.value = savedVoice;
            }
        }

        function setupEventListeners() {
            voiceBtn.addEventListener('click', handleMicClick);
            settingsBtn.addEventListener('click', () => settingsModal.classList.remove('hidden', 'flex'));
            settingsBtn.addEventListener('click', () => settingsModal.classList.add('flex'));
            closeModal.addEventListener('click', () => settingsModal.classList.add('hidden'));
            saveSettingsBtn.addEventListener('click', saveSettings);
            clearChatBtn.addEventListener('click', () => {
                chatMessages.innerHTML = '';
                showNotification('Chat cleared');
                settingsModal.classList.add('hidden');
            });
            settingsModal.addEventListener('click', (e) => {
                if (e.target === settingsModal) settingsModal.classList.add('hidden');
            });
        }

        // --- Robust Speech Recognition for Mobile ---
        function initSpeechRecognition() {
            if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
                const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                recognition = new SpeechRecognition();
                recognition.continuous = true; 
                recognition.interimResults = true; 
                recognition.lang = 'en-US';

                recognition.onstart = () => {
                    state.isListening = true;
                    updateUIState('listening');
                    state.currentSessionText = '';
                };

                // FIXED: Logic to prevent duplicates
                recognition.onresult = (event) => {
                    // Rebuild current session text from scratch every time
                    // This avoids appending duplicates on Android Chrome
                    let sessionFullText = '';
                    
                    for (let i = 0; i < event.results.length; ++i) {
                        sessionFullText += event.results[i][0].transcript;
                    }
                    
                    state.currentSessionText = sessionFullText;

                    // Display Total = Saved + Current
                    const totalDisplay = (state.savedTranscript + ' ' + state.currentSessionText).trim();
                    
                    if(totalDisplay.length > 0) {
                        transcriptPreview.style.display = 'block';
                        transcriptPreview.textContent = totalDisplay.slice(-100); // Show last 100 chars
                        transcriptPreview.scrollTop = transcriptPreview.scrollHeight;
                    }
                };

                recognition.onerror = (event) => {
                    if(event.error === 'no-speech') return;
                    if(event.error === 'not-allowed') {
                        state.shouldBeListening = false;
                        updateUIState('idle');
                        showNotification('Mic permission denied', 'error');
                    }
                };
                
                recognition.onend = () => {
                    state.isListening = false;
                    
                    // Commit current session to saved
                    if(state.currentSessionText) {
                        state.savedTranscript += state.currentSessionText + ' ';
                        state.currentSessionText = '';
                    }

                    if (state.shouldBeListening) {
                        // Restart loop
                        try {
                            recognition.start();
                        } catch(e) {
                            state.shouldBeListening = false;
                            updateUIState('idle');
                        }
                    } else {
                        // User stopped
                        processRecordedText();
                    }
                };
            } else {
                voiceBtn.disabled = true;
                voiceStatus.textContent = 'Browser not supported';
                showNotification('Use Chrome for voice features', 'error');
            }
        }

        function handleMicClick() {
            if (!recognition) return;
            
            // Need audio context user gesture for mobile audio playback later
            if (!audioContext) audioContext = new (window.AudioContext || window.webkitAudioContext)();
            if (audioContext.state === 'suspended') audioContext.resume();

            if (state.shouldBeListening) {
                // STOP & SEND ACTION
                state.shouldBeListening = false; 
                recognition.stop();
            } else {
                // START LISTENING ACTION
                state.savedTranscript = ''; // Reset for new message
                state.currentSessionText = '';
                state.shouldBeListening = true;
                try {
                    recognition.start();
                } catch(e) {
                    console.error(e);
                    state.shouldBeListening = false;
                }
            }
        }

        function processRecordedText() {
            transcriptPreview.style.display = 'none';
            updateUIState('idle');

            const textToSend = state.savedTranscript.trim();
            if (textToSend.length > 1) {
                addUserMessage(textToSend);
                processWithGemini(textToSend);
            } else {
                // Only warn if empty
            }
            // Reset
            state.savedTranscript = '';
            state.currentSessionText = '';
        }

        // --- Gemini Interaction ---

        async function processWithGemini(userText) {
            if (!state.apiKey) {
                addBotMessage("Please enter your API Key in settings to start chatting!");
                return;
            }

            updateUIState('thinking');

            try {
                // 1. Get Text
                const textResponse = await fetchGeminiText(userText);
                addBotMessage(textResponse);
                
                // 2. Get Audio
                updateUIState('generating_audio');
                await speakGemini(textResponse);
                
            } catch (error) {
                console.error(error);
                let msg = error.message;
                if(msg.includes("429") || msg.includes("Quota")) {
                    msg = "Traffic limit. Please wait a moment.";
                }
                addBotMessage(`Error: ${msg}`);
                updateUIState('idle');
            }
        }

        async function fetchGeminiText(input) {
            const url = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-09-2025:generateContent?key=${state.apiKey}`;
            
            const contextPrompt = `
                You are Professor Emma, an English Tutor.
                Goal: Help Spanish speaker.
                Rule: If user makes mistake: Quote mistake in <span class="error-mark">error</span>, correct in <span class="correction-mark">correction</span>.
                Response: Concise (max 2 sentences). Natural English.
                User: "${input}"
            `;

            const payload = { contents: [{ parts: [{ text: contextPrompt }] }] };

            const response = await fetch(url, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(payload)
            });

            if (!response.ok) {
                const errorData = await response.json().catch(() => ({}));
                throw new Error(errorData.error?.message || `API Error ${response.status}`);
            }
            
            const data = await response.json();
            return data.candidates[0].content.parts[0].text;
        }

        // --- Translation ---
        async function translateMessage(btn) {
            if (!state.apiKey) return showNotification("No API Key", "error");
            
            const messageDiv = btn.parentElement;
            const textContainer = messageDiv.querySelector('.text-content');
            let translationDiv = messageDiv.querySelector('.translation-result');
            
            if (translationDiv) {
                translationDiv.style.display = translationDiv.style.display === 'none' ? 'block' : 'none';
                return;
            }

            btn.innerHTML = '<i class="fas fa-spinner fa-spin"></i>';
            btn.disabled = true;

            try {
                const content = textContainer.innerHTML.trim();
                const url = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-09-2025:generateContent?key=${state.apiKey}`;
                
                const prompt = `Translate to Spanish. Preserve HTML <span class="error-mark"> and <span class="correction-mark">. Do NOT translate content inside spans. Input: "${content}"`;
                
                const response = await fetch(url, {
                    method: 'POST', 
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({ contents: [{ parts: [{ text: prompt }] }] })
                });

                const data = await response.json();
                let trans = data.candidates[0].content.parts[0].text.replace(/```html|```/g, '').trim();
                
                translationDiv = document.createElement('div');
                translationDiv.className = 'translation-result text-[15px] text-indigo-600 mt-3 pt-2 border-t border-gray-100 font-medium';
                translationDiv.innerHTML = trans;
                messageDiv.insertBefore(translationDiv, btn);
            } catch(e) {
                console.error(e);
            } finally {
                btn.innerHTML = '<i class="fas fa-language"></i>';
                btn.disabled = false;
            }
        }

        // --- Audio ---
        async function speakGemini(text) {
            const cleanText = text.replace(/<[^>]*>/g, '');
            const url = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent?key=${state.apiKey}`;
            
            try {
                const response = await fetch(url, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        contents: [{ parts: [{ text: cleanText }] }],
                        generationConfig: {
                            responseModalities: ["AUDIO"],
                            speechConfig: { voiceConfig: { prebuiltVoiceConfig: { voiceName: state.voice } } }
                        }
                    })
                });

                if (!response.ok) throw new Error(`TTS Error ${response.status}`);

                const data = await response.json();
                if (data.candidates && data.candidates[0].content.parts[0].inlineData) {
                    await playPCM16(data.candidates[0].content.parts[0].inlineData.data);
                }
            } catch (e) {
                console.warn("TTS failed, using fallback");
                speakNative(cleanText); // Silent fallback
            }
        }

        async function playPCM16(base64Data) {
            updateUIState('speaking');
            const binaryString = window.atob(base64Data);
            const len = binaryString.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) { bytes[i] = binaryString.charCodeAt(i); }
            
            const wavBytes = getWavBytes(bytes.buffer, { isFloat: false, numChannels: 1, sampleRate: 24000 });
            const blob = new Blob([wavBytes], { type: 'audio/wav' });
            const audioUrl = URL.createObjectURL(blob);
            const audio = new Audio(audioUrl);
            audio.onended = () => { updateUIState('idle'); URL.revokeObjectURL(audioUrl); };
            await audio.play();
        }

        function getWavBytes(buffer, options) {
            const type = options.isFloat ? Float32Array : Uint16Array;
            const numFrames = buffer.byteLength / type.BYTES_PER_ELEMENT;
            const headerBytes = getWavHeader(Object.assign({}, options, { numFrames }));
            const wavBytes = new Uint8Array(headerBytes.length + buffer.byteLength);
            wavBytes.set(headerBytes, 0);
            wavBytes.set(new Uint8Array(buffer), headerBytes.length);
            return wavBytes;
        }

        function getWavHeader(options) {
            const numFrames = options.numFrames;
            const numChannels = options.numChannels || 2;
            const sampleRate = options.sampleRate || 44100;
            const bytesPerSample = options.isFloat ? 4 : 2;
            const format = options.isFloat ? 3 : 1;
            const blockAlign = numChannels * bytesPerSample;
            const byteRate = sampleRate * blockAlign;
            const dataSize = numFrames * blockAlign;
            const buffer = new ArrayBuffer(44);
            const dv = new DataView(buffer);
            let p = 0;
            function writeString(s) { for (let i = 0; i < s.length; i++) { dv.setUint8(p + i, s.charCodeAt(i)); } p += s.length; }
            function writeUint32(d) { dv.setUint32(p, d, true); p += 4; }
            function writeUint16(d) { dv.setUint16(p, d, true); p += 2; }
            writeString('RIFF'); writeUint32(dataSize + 36); writeString('WAVE');
            writeString('fmt '); writeUint32(16); writeUint16(format);
            writeUint16(numChannels); writeUint32(sampleRate); writeUint32(byteRate);
            writeUint16(blockAlign); writeUint16(bytesPerSample * 8);
            writeString('data'); writeUint32(dataSize);
            return new Uint8Array(buffer);
        }

        function speakNative(text) {
            updateUIState('speaking');
            const cleanText = text.replace(/<[^>]*>/g, '');
            const utterance = new SpeechSynthesisUtterance(cleanText);
            utterance.lang = 'en-US';
            utterance.onend = () => updateUIState('idle');
            const voices = speechSynthesis.getVoices();
            const preferred = voices.find(v => v.name.includes('Google US English')) || voices.find(v => v.lang === 'en-US');
            if(preferred) utterance.voice = preferred;
            speechSynthesis.speak(utterance);
        }

        // --- UI Logic ---
        function addUserMessage(text) {
            const div = document.createElement('div');
            div.className = 'message self-end w-[85%] max-w-xs bg-primary text-white rounded-2xl rounded-br-none p-4 shadow-md';
            div.innerHTML = `<div class="text-[15px]">${text}</div>`;
            chatMessages.appendChild(div);
            scrollToBottom();
        }

        function addBotMessage(html) {
            const div = document.createElement('div');
            div.className = 'message self-start w-[90%] max-w-sm bg-white border border-gray-100 rounded-2xl rounded-tl-none p-4 shadow-sm relative pb-8';
            div.innerHTML = `
                <div class="text-content text-gray-700 leading-relaxed text-[15px]">${html}</div>
                <button onclick="translateMessage(this)" class="absolute bottom-2 right-2 text-indigo-500 hover:text-indigo-700 hover:scale-110 transition-all bg-indigo-50 p-1.5 rounded-full w-8 h-8 flex items-center justify-center shadow-sm" title="Translate">
                    <i class="fas fa-language"></i>
                </button>
            `;
            chatMessages.appendChild(div);
            scrollToBottom();
        }

        function updateUIState(status) {
            voiceBtn.classList.remove('listening', 'speaking');
            soundWave.style.display = 'none';
            typingIndicator.classList.add('hidden');
            
            switch(status) {
                case 'listening':
                    voiceBtn.classList.add('listening');
                    voiceBtn.innerHTML = '<i class="fas fa-paper-plane text-white text-2xl"></i>';
                    voiceStatus.textContent = 'Tap to Send';
                    soundWave.style.display = 'flex';
                    break;
                case 'thinking':
                    voiceBtn.disabled = true;
                    typingIndicator.classList.remove('hidden');
                    statusText.textContent = 'Emma is thinking...';
                    voiceStatus.textContent = 'Processing';
                    break;
                case 'generating_audio':
                    voiceBtn.disabled = true;
                    typingIndicator.classList.remove('hidden');
                    statusText.textContent = 'Emma is replying...';
                    break;
                case 'speaking':
                    voiceBtn.classList.add('speaking');
                    voiceBtn.innerHTML = '<i class="fas fa-volume-up"></i>';
                    voiceBtn.disabled = false;
                    voiceStatus.textContent = 'Speaking...';
                    soundWave.style.display = 'flex';
                    break;
                case 'idle':
                default:
                    voiceBtn.innerHTML = '<i class="fas fa-microphone"></i>';
                    voiceBtn.disabled = false;
                    voiceStatus.textContent = 'Tap to speak';
                    break;
            }
        }

        function scrollToBottom() {
            chatMessages.scrollTop = chatMessages.scrollHeight;
        }

        function saveSettings() {
            const key = apiKeyInput.value.trim();
            const voice = voiceSelect.value;
            if (key) {
                state.apiKey = key;
                localStorage.setItem('tutor_api_key', key);
            }
            state.voice = voice;
            localStorage.setItem('tutor_voice', voice);
            settingsModal.classList.add('hidden');
            showNotification('Settings saved');
        }

        function showNotification(text, type = 'success') {
            notificationText.textContent = text;
            const container = notification.querySelector('div');
            const icon = container.querySelector('i');
            
            if (type === 'error') {
                container.className = 'w-6 h-6 rounded-full bg-red-100 flex items-center justify-center text-red-500';
                icon.className = 'fas fa-exclamation text-xs';
            } else {
                container.className = 'w-6 h-6 rounded-full bg-green-100 flex items-center justify-center text-green-500';
                icon.className = 'fas fa-check text-xs';
            }
            
            notification.classList.remove('-translate-y-24', 'opacity-0');
            notification.classList.add('translate-y-6');
            setTimeout(() => {
                notification.classList.add('-translate-y-24', 'opacity-0');
                notification.classList.remove('translate-y-6');
            }, 3000);
        }

        speechSynthesis.onvoiceschanged = () => {};
    </script>
</body>
</html>
